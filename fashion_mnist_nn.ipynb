{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Fashion MNSIT dataset which is directly available in TensorFlow\n",
    "The Fashion MNIST dataset is a collection of grayscale 28x28 pixel clothing images. It consists of a training set of 60,000 images and a test set of 10,000 images. Each image is mapped to a single label from the following 10 classes:\n",
    "- 0: T-shirt/top\n",
    "- 1: Trouser\n",
    "- 2: Pullover\n",
    "- 3: Dress\n",
    "- 4: Coat\n",
    "- 5: Sandal\n",
    "- 6: Shirt\n",
    "- 7: Sneaker\n",
    "- 8: Bag\n",
    "- 9: Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test split of the Fashion MNIST dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 6\n",
      "\n",
      "IMAGE PIXEL ARRAY:\n",
      " [[  0   0   0   0   0   0   0   0   0  62  28   0   0   0   0   0   0   2  61  22   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 181 221 222  64  58 109  47  11  59 108  59  49 215 200 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 230 218 231 225 157   0   0  31  49  30   0   0 163 232 235 227 213   0   0   0   0   0]\n",
      " [  0   0   0   0   0  75 240 185 213 231 224 232  89   1  14  52 127 234 228 229 215 176 238 112   0   0   0   0]\n",
      " [  0   0   0   0   0 196 221 217 159 243 229 185 255 249 220 255 199 236 222 239 166 214 211 214   0   0   0   0]\n",
      " [  0   0   0   0  19 220 210 234 163 225 207 162 220 163 152 204 182 158 255 185 197 222 207 240 147   0   0   0]\n",
      " [  0   0   0   0   0 238 219 230 205 239 184 214 183 163 160 173 221 180 236 177 236 217 230 191   0   0   0   0]\n",
      " [  0   0   0   0   0  61 237 236 212 245 242 200 154 202 206 153 202 255 199 217 228 232 213   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  50 242 228 233 232 238 224 236 239 231 240 231 228 232 232 255   3   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0 106 246 227 229 232 237 232 230 230 232 229 231 229 248 130   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0  80 233 225 235 231 230 230 233 231 232 230 231 230 246   5   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0  37 243 230 232 230 231 231 229 231 233 233 229 233 239  13   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 255 233 232 231 231 231 233 232 231 232 228 236 229   0   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216 244 226 228 233 231 232 231 230 231 229 237 253   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 224 241 223 229 234 232 231 231 228 229 229 237 247   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 236 238 223 230 235 233 229 234 232 229 227 235 252   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 246 235 225 232 235 233 228 233 234 229 230 231 228   0   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 255 233 226 232 234 232 228 232 236 231 230 228 238  27   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0   4 232 232 228 232 234 232 228 230 231 230 228 228 242  59   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0  23 241 228 226 233 234 232 228 232 234 231 228 227 247 104   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   4   0  40 243 227 228 232 234 233 229 232 231 231 228 226 246 148   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   4   0  52 244 225 231 231 233 232 230 232 230 231 228 227 245 185   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   4   0  58 244 224 230 230 232 231 229 232 231 231 227 223 243 199   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   4   0  53 243 225 230 229 233 231 229 233 230 230 229 226 239 221   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   4   0  47 243 224 232 229 234 230 229 232 230 229 229 228 237 237   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   4   0  30 239 225 227 226 233 229 229 234 230 230 230 227 234 235   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   3   0  21 242 229 247 251 250 247 243 238 241 241 236 233 239 255   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 213 164 161 164 154 158 177 170 182 173 159 167 208 171   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17b0c6560>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhwUlEQVR4nO3dfXCV9d3n8c/JSXJ4SoIB8iQBA6KoQLylklKUYskC6d4OKNv1aWfBdWG0wSlSq5OOinp3Ji3ubR29Ke5DC3VXfJoVWGmHjqIJawt0QSjF2pTEWIIkQemdHAjkgXN++wc17REQfxcn+Sbh/Zo5M+Sc65PrlysXfM7FOfkm5JxzAgCgl6VYLwAAcHGigAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGAi1XoBnxePx3X48GFlZGQoFApZLwcA4Mk5p2PHjqmgoEApKee+zulzBXT48GEVFhZaLwMAcIEaGho0evTocz7e5wooIyNDknSDvqlUpRmvBsl28t9O9c4Mq/mLdyZWW++dwd9JCXtH2ude650Z9n6Td+bUwY+9M+hdp9Sld/XL7n/Pz6XHCmj16tV66qmn1NTUpOLiYj333HOaNm3aeXOf/bdbqtKUGqKABprUtEH+mXDEOxPi3LkwIf8CCvS9TfH/3orvbd/31wmj53sZpUfehPDKK69oxYoVWrlypd577z0VFxdr7ty5OnLkSE/sDgDQD/VIAT399NNasmSJ7r77bl199dV6/vnnNWTIEP3sZz/rid0BAPqhpBdQZ2endu/erdLS0r/tJCVFpaWl2r59+xnbd3R0KBqNJtwAAANf0gvo008/VSwWU25ubsL9ubm5amo68wXHyspKZWVldd94BxwAXBzMfxC1oqJCra2t3beGhgbrJQEAekHS3wU3cuRIhcNhNTc3J9zf3NysvLy8M7aPRCKKRAK8EwYA0K8l/QooPT1dU6dO1datW7vvi8fj2rp1q6ZPn57s3QEA+qke+TmgFStWaNGiRfrKV76iadOm6ZlnnlFbW5vuvvvuntgdAKAf6pECuu222/TJJ5/oscceU1NTk6699lpt2bLljDcmAAAuXiHnnLNexN+LRqPKysrSLM1nEkIvCb9TECj3HwvOfFv9+aSE4t6Z5x6+3TsT7vDfjyQdmep/zl1addI7k/b7D70zJ2Zc4Z058g/B/g7l7OnyzqS2xbwz/+4nv/LOHDjp/0T29b3XeWck6Yp7dgXKXexOuS5VaZNaW1uVmZl5zu3M3wUHALg4UUAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMNEj07Bhp6Jun3fmo67DgfZVkPav3pmW2BDvzCd3nPDOjP33v/fOSFLhL/0z4av9h4R2XjveOzPkwxbvTOEvDnhngmrceJV3ZvIg/9+AfP3geu/Mv/n6+94ZSTrw/pm/RPN8Nl9zSaB9XYy4AgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmGAadh/W+h++6p0pSP21d+bZj2d7ZyTpphF/8s4UD/6zd+aH/7DBOzPqw6h3RpKW/Zdl3pmcNdu9M+lHsr0zHcWXeWc+WuJ/DknSS7c8551piflPnG53ad6Z37cXemde+fgr3hlJ+pcJL3tnfvL4d70zYx7/jXdmIOAKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgImQc85ZL+LvRaNRZWVlaZbmKzXkP6hwIBn//wZ5Z2Zm1nhn2uIR74wk/fP7pd6ZLdOe984c6Mryzqz++BveGUl6/fI3vTOt8ZPemc1to70zd2Uc9c4sbww2hHNxtv9Q2z915XhnJqc3emfu2ne3d+aey4MN++yI+/8bFEnp8s78n6tHeGf6slOuS1XapNbWVmVmZp5zO66AAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmEi1XsDFIvXSAu/MjMyd3pmGrmzvzNeH/tE7I0mpqTHvzN4O/4GV+06O8c4cODrKOyNJL+b6D4X80QdzvDMnTvgPgP3g6t3emdpjwY7DHR/+Z+/MBzP+p3fm1tr53pmv5X/knRmVGvXOSNKf2vO9M/+Y8XvvzD///H7vzIRF73ln+hqugAAAJiggAICJpBfQ448/rlAolHCbOHFisncDAOjneuQ1oGuuuUZvvfXW33aSyktNAIBEPdIMqampysvL64lPDQAYIHrkNaADBw6ooKBA48aN01133aWDBw+ec9uOjg5Fo9GEGwBg4Et6AZWUlGjdunXasmWL1qxZo/r6et144406duzYWbevrKxUVlZW962wsDDZSwIA9EFJL6CysjJ961vf0pQpUzR37lz98pe/VEtLi1599dWzbl9RUaHW1tbuW0NDQ7KXBADog3r83QHDhw/XFVdcodra2rM+HolEFIn4/1AeAKB/6/GfAzp+/Ljq6uqUn+//E8UAgIEr6QX04IMPqrq6Wh999JF+85vf6JZbblE4HNYdd9yR7F0BAPqxpP8X3KFDh3THHXfo6NGjGjVqlG644Qbt2LFDo0YFm0kFABiYkl5AL7/8crI/5YBw6uPD3plrI4e8MzEX8s6ciAd7De6Won3emQlpn3pnfnb4Ru/MvVf+X++MJL3SdH2gnK9IpMs7U9U0wTuzrOgd74wkrYt/zTuzt6PDO9PaOdg781jhZu/M7vax3hlJumHon7wzPzhc5p0ZCINFg2AWHADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABM9/gvpENy37/+Od+a55571zsQDDDCVpEtS27wzw1Pi3pkfX/a/vTP/8ulM74wk/fFwrnfmlom/884MSen0zvyv96d5Z/bkBhvCuWXiL7wzyxtneGfuvPS33pkjsWHemYkR/2HAkvTeySLvTPP0aKB9XYy4AgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmAg555z1Iv5eNBpVVlaWZmm+UkNp1svpd2I3Xeed+e/r/CdoS9KBrku8M5kp7d6ZmPyndQ9P6fDOSNKBrlHemctSj3pnIqGYd+aT+BDvTF7Yf2K5JDXFhnpn2uP+f1+HBvw++ZoxKNhz7XljvuKdcadO+e8oFGAifd/6pzvBKdelKm1Sa2urMjMzz7kdV0AAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMpFovAMkVfuc978w//teHAu3rnfue8s6815HtnUkL+Q93bIl7RyRJ49I+9c4ci6d7Z1rig70zQXwSC7afLhf2zgxK6fLOtDv/AabXpR/zzox7bYV3RpImnNoRKOetDw8W7UlcAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDBMNK+LMV/IKTiMe/IkMZggxA/7BrknekMMORyVNh/+GSb8x8QKkl/iQ0JlPM1KOQ/uLNTAc6HgMLqneGYQfbTFSBzxUN7vDOSgh2FUCjAjhhGCgBAr6GAAAAmvAto27Ztuvnmm1VQUKBQKKSNGzcmPO6c02OPPab8/HwNHjxYpaWlOnDgQLLWCwAYILwLqK2tTcXFxVq9evVZH1+1apWeffZZPf/889q5c6eGDh2quXPnqr29/YIXCwAYOLzfhFBWVqaysrKzPuac0zPPPKNHHnlE8+fPlyS98MILys3N1caNG3X77bdf2GoBAANGUl8Dqq+vV1NTk0pLS7vvy8rKUklJibZv337WTEdHh6LRaMINADDwJbWAmpqaJEm5ubkJ9+fm5nY/9nmVlZXKysrqvhUWFiZzSQCAPsr8XXAVFRVqbW3tvjU0NFgvCQDQC5JaQHl5eZKk5ubmhPubm5u7H/u8SCSizMzMhBsAYOBLagEVFRUpLy9PW7du7b4vGo1q586dmj59ejJ3BQDo57zfBXf8+HHV1tZ2f1xfX6+9e/cqOztbY8aM0fLly/WDH/xAEyZMUFFRkR599FEVFBRowYIFyVw3AKCf8y6gXbt26aabbur+eMWKFZKkRYsWad26dXrooYfU1tampUuXqqWlRTfccIO2bNmiQYP854YBAAYu7wKaNWuW3BcMzguFQnryySf15JNPXtDCIIVS/Icaurj/fkbsDfbW94LUk96ZdpcWIOM/Mzfugv3vckoowAEMIMiw1LSQ/6DZoENFwwGGpQb5moaGOr0zR2P+fy9Shg31zkhSrKPDOxMK+w+NdadOeWcGAvN3wQEALk4UEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABP+Y4bRa1w82CRj7/3seT9QbkzqMO/M4VP+U5ZjCjD9uJemWgcVZAp0kOPQKf/JzJIUlv/xiwWYQD4oxX8K9OFYhncmdvQv3pmgeuvv7UDAFRAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATDCPty+Ix6xV8of/WWuCd+ebQP3lnftc50juTpmDHLjOl3TsTZOBnkMGisQDPF+MBBoRKUoDlKRxgAGxKyH9w58xB/oNcV3knLoDr24Nw+xKugAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJhgGCkCy0mNemc6/GdPqj2e7p0ZFG7z35GklAADNcOudwaLBtHp/AelSlI4yDTSXtIa9x8Yi76JKyAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmGEbal4UCDIR0AaZ9BnRZ6lHvTHvA4Zi+wgp2HILk4gEyQY5DRor/EM5wiv9wVUlqd2nemS7n/89Jl/N/DpyR0jvnEHoeV0AAABMUEADAhHcBbdu2TTfffLMKCgoUCoW0cePGhMcXL16sUCiUcJs3b16y1gsAGCC8C6itrU3FxcVavXr1ObeZN2+eGhsbu28vvfTSBS0SADDweL9qWFZWprKysi/cJhKJKC8vL/CiAAADX4+8BlRVVaWcnBxdeeWVuu+++3T06LnfLdXR0aFoNJpwAwAMfEkvoHnz5umFF17Q1q1b9aMf/UjV1dUqKytTLBY76/aVlZXKysrqvhUWFiZ7SQCAPijpPwd0++23d/958uTJmjJlisaPH6+qqirNnj37jO0rKiq0YsWK7o+j0SglBAAXgR5/G/a4ceM0cuRI1dbWnvXxSCSizMzMhBsAYODr8QI6dOiQjh49qvz8/J7eFQCgH/H+L7jjx48nXM3U19dr7969ys7OVnZ2tp544gktXLhQeXl5qqur00MPPaTLL79cc+fOTerCAQD9m3cB7dq1SzfddFP3x5+9frNo0SKtWbNG+/bt089//nO1tLSooKBAc+bM0T/90z8pEokkb9UAgH7Pu4BmzZol9wUDL3/1q19d0ILQfxSknvLONJzyH3KZFvLfT5BMb4oFGMIZD5BJC5393afnE2QY6aBQl3emzaV7Z6pP+q+tN4XC/sNS3am+fb72FGbBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMJP1XciOJQgGeH7hg04+DyAkP9c582OW/vnAo7p0JKqZQr2SCCLKfQQp27IJM0Q4yrbs97j/Z+tLUqHcmPGGcd0aSYgc+DJTDl8MVEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMMI+3DQin+wyddgNmTobR0/5CkX7cHGXTp/zWlqfcGrPZlXc7/r2s04HPMIINFO1040L58DQkwKPXEFSMC7SvCMNIexRUQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAEwwjhcKX5gXK5YVPeGfqui7xznTJf8hlWM4709elhU4FyAQb5NquNP9QgGGk8QDPgTMCDOn9ZEqAr0fS6F8EiuFL4goIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACYaR9mWh3nl+EBuVFSiX5j8TMtDwyTT5D9SMKcDiFOwZWZDBp+FQPMCe/LW7YEM4e0uQ71OQI3fyqvYAqWBcfOANwu0pXAEBAExQQAAAE14FVFlZqeuvv14ZGRnKycnRggULVFNTk7BNe3u7ysvLNWLECA0bNkwLFy5Uc3NzUhcNAOj/vAqourpa5eXl2rFjh9588011dXVpzpw5amtr697mgQce0BtvvKHXXntN1dXVOnz4sG699dakLxwA0L95vQlhy5YtCR+vW7dOOTk52r17t2bOnKnW1lb99Kc/1fr16/WNb3xDkrR27VpdddVV2rFjh7761a8mb+UAgH7tgl4Dam1tlSRlZ2dLknbv3q2uri6VlpZ2bzNx4kSNGTNG27dvP+vn6OjoUDQaTbgBAAa+wAUUj8e1fPlyzZgxQ5MmTZIkNTU1KT09XcOHD0/YNjc3V01NTWf9PJWVlcrKyuq+FRYWBl0SAKAfCVxA5eXl2r9/v15++eULWkBFRYVaW1u7bw0NDRf0+QAA/UOgH0RdtmyZNm/erG3btmn06NHd9+fl5amzs1MtLS0JV0HNzc3Ky8s76+eKRCKKRCJBlgEA6Me8roCcc1q2bJk2bNigt99+W0VFRQmPT506VWlpadq6dWv3fTU1NTp48KCmT5+enBUDAAYEryug8vJyrV+/Xps2bVJGRkb36zpZWVkaPHiwsrKydM8992jFihXKzs5WZmam7r//fk2fPp13wAEAEngV0Jo1ayRJs2bNSrh/7dq1Wrx4sSTpxz/+sVJSUrRw4UJ1dHRo7ty5+slPfpKUxQIABg6vAnLu/EP2Bg0apNWrV2v16tWBF4Xe1ZWZHigX5B0snS7snRke7vDOxAK+vyb8Jc7xM/flP1AzyADTIOIu2HFI6aVhqUGOQyzA9+jay4K9uant/JucKe4/PPdixSw4AIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAICJQL8RFQNLLNJ7z0PiAZ7zBJ3oHEQswBToIJO3g0zQTvNO9N5UaynY97Yt7v/bkLu8E9KYof8aICV9ECiFL4srIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYYRgqldAYbWBkklRIo5S/IsE9JGiQXYF+9IxxgbV29OMg1LXTKOzMoxf/71Bb3/5q+OqzOOyNJH2hsoBy+HK6AAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmGAYKRTu6J0BoZIUD/CcJ8iQy5hL885IUkrI/1jE48H25SvogNW+vK+0AKNcuwKcQ1dHGr0zpzGMtCdxBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEw0ihtE+PB8q1xf2fv6TIf9jnsfhg70zQYZpDXWev7ctXWijA4E4X7K94WC5QzleQwaLtLuyd6a2vJ7BQgHPI9fGv6UvgCggAYIICAgCY8CqgyspKXX/99crIyFBOTo4WLFigmpqahG1mzZqlUCiUcLv33nuTumgAQP/nVUDV1dUqLy/Xjh079Oabb6qrq0tz5sxRW1tbwnZLlixRY2Nj923VqlVJXTQAoP/zeoVyy5YtCR+vW7dOOTk52r17t2bOnNl9/5AhQ5SXl5ecFQIABqQLeg2otbVVkpSdnZ1w/4svvqiRI0dq0qRJqqio0IkTJ875OTo6OhSNRhNuAICBL/DbsOPxuJYvX64ZM2Zo0qRJ3fffeeedGjt2rAoKCrRv3z49/PDDqqmp0euvv37Wz1NZWaknnngi6DIAAP1U4AIqLy/X/v379e677ybcv3Tp0u4/T548Wfn5+Zo9e7bq6uo0fvz4Mz5PRUWFVqxY0f1xNBpVYWFh0GUBAPqJQAW0bNkybd68Wdu2bdPo0aO/cNuSkhJJUm1t7VkLKBKJKBKJBFkGAKAf8yog55zuv/9+bdiwQVVVVSoqKjpvZu/evZKk/Pz8QAsEAAxMXgVUXl6u9evXa9OmTcrIyFBTU5MkKSsrS4MHD1ZdXZ3Wr1+vb37zmxoxYoT27dunBx54QDNnztSUKVN65AsAAPRPXgW0Zs0aSad/2PTvrV27VosXL1Z6erreeustPfPMM2pra1NhYaEWLlyoRx55JGkLBgAMDN7/BfdFCgsLVV1dfUELAgBcHJiG3Zc5/8nRQYSOnwyUGxTyX9/QlA7vTHG6/8+GDQmleWckKR5gWne7a/fOnAgwyfhY3H8K9IhU/+Md1LG4/zFvd13emYyQf+aq9CHeGfQ8hpECAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwwTDSPszF/QdWBnGq4VCg3Obj13hn/seBr3lnYnH/50nhlGCDXE+eTPffV6r/vgouafXOtHX6r23kkDbvjCS1tA/2zvzluP/Az8GRTu/MwrG/8878p48neWckKVN1gXLeAgynHQi4AgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAiT43C879dSbSKXVJF+d4pL9xAeaZuVjy13EO7cdPeWdiJzr8MwFmwSngLLj4yQC5ALPgTqUHOA6d/n8hupz/rDVJOtXuf8xjJwJkYl3emfbj/plYm//xlqRTzn9f+Ou/3/rbv+fnEnLn26KXHTp0SIWFhdbLAABcoIaGBo0ePfqcj/e5AorH4zp8+LAyMjIUCoUSHotGoyosLFRDQ4MyMzONVmiP43Aax+E0jsNpHIfT+sJxcM7p2LFjKigoUErKua+M+9x/waWkpHxhY0pSZmbmRX2CfYbjcBrH4TSOw2kch9Osj0NWVtZ5t+FNCAAAExQQAMBEvyqgSCSilStXKhKJWC/FFMfhNI7DaRyH0zgOp/Wn49Dn3oQAALg49KsrIADAwEEBAQBMUEAAABMUEADARL8poNWrV+uyyy7ToEGDVFJSot/+9rfWS+p1jz/+uEKhUMJt4sSJ1svqcdu2bdPNN9+sgoIChUIhbdy4MeFx55wee+wx5efna/DgwSotLdWBAwdsFtuDznccFi9efMb5MW/ePJvF9pDKykpdf/31ysjIUE5OjhYsWKCampqEbdrb21VeXq4RI0Zo2LBhWrhwoZqbm41W3DO+zHGYNWvWGefDvffea7Tis+sXBfTKK69oxYoVWrlypd577z0VFxdr7ty5OnLkiPXSet0111yjxsbG7tu7775rvaQe19bWpuLiYq1evfqsj69atUrPPvusnn/+ee3cuVNDhw7V3Llz1d7e3ssr7VnnOw6SNG/evITz46WXXurFFfa86upqlZeXa8eOHXrzzTfV1dWlOXPmqK2trXubBx54QG+88YZee+01VVdX6/Dhw7r11lsNV518X+Y4SNKSJUsSzodVq1YZrfgcXD8wbdo0V15e3v1xLBZzBQUFrrKy0nBVvW/lypWuuLjYehmmJLkNGzZ0fxyPx11eXp576qmnuu9raWlxkUjEvfTSSwYr7B2fPw7OObdo0SI3f/58k/VYOXLkiJPkqqurnXOnv/dpaWnutdde697mgw8+cJLc9u3brZbZ4z5/HJxz7utf/7r7zne+Y7eoL6HPXwF1dnZq9+7dKi0t7b4vJSVFpaWl2r59u+HKbBw4cEAFBQUaN26c7rrrLh08eNB6Sabq6+vV1NSUcH5kZWWppKTkojw/qqqqlJOToyuvvFL33Xefjh49ar2kHtXa2ipJys7OliTt3r1bXV1dCefDxIkTNWbMmAF9Pnz+OHzmxRdf1MiRIzVp0iRVVFToxIkTFss7pz43jPTzPv30U8ViMeXm5ibcn5ubqz/+8Y9Gq7JRUlKidevW6corr1RjY6OeeOIJ3Xjjjdq/f78yMjKsl2eiqalJks56fnz22MVi3rx5uvXWW1VUVKS6ujp9//vfV1lZmbZv365wOGy9vKSLx+Navny5ZsyYoUmTJkk6fT6kp6dr+PDhCdsO5PPhbMdBku68806NHTtWBQUF2rdvnx5++GHV1NTo9ddfN1xtoj5fQPibsrKy7j9PmTJFJSUlGjt2rF599VXdc889hitDX3D77bd3/3ny5MmaMmWKxo8fr6qqKs2ePdtwZT2jvLxc+/fvvyheB/0i5zoOS5cu7f7z5MmTlZ+fr9mzZ6uurk7jx4/v7WWeVZ//L7iRI0cqHA6f8S6W5uZm5eXlGa2qbxg+fLiuuOIK1dbWWi/FzGfnAOfHmcaNG6eRI0cOyPNj2bJl2rx5s955552EX9+Sl5enzs5OtbS0JGw/UM+Hcx2HsykpKZGkPnU+9PkCSk9P19SpU7V169bu++LxuLZu3arp06cbrsze8ePHVVdXp/z8fOulmCkqKlJeXl7C+RGNRrVz586L/vw4dOiQjh49OqDOD+ecli1bpg0bNujtt99WUVFRwuNTp05VWlpawvlQU1OjgwcPDqjz4XzH4Wz27t0rSX3rfLB+F8SX8fLLL7tIJOLWrVvn/vCHP7ilS5e64cOHu6amJuul9arvfve7rqqqytXX17tf//rXrrS01I0cOdIdOXLEemk96tixY27Pnj1uz549TpJ7+umn3Z49e9yf//xn55xzP/zhD93w4cPdpk2b3L59+9z8+fNdUVGRO3nypPHKk+uLjsOxY8fcgw8+6LZv3+7q6+vdW2+95a677jo3YcIE197ebr30pLnvvvtcVlaWq6qqco2Njd23EydOdG9z7733ujFjxri3337b7dq1y02fPt1Nnz7dcNXJd77jUFtb65588km3a9cuV19f7zZt2uTGjRvnZs6cabzyRP2igJxz7rnnnnNjxoxx6enpbtq0aW7Hjh3WS+p1t912m8vPz3fp6enu0ksvdbfddpurra21XlaPe+edd5ykM26LFi1yzp1+K/ajjz7qcnNzXSQScbNnz3Y1NTW2i+4BX3QcTpw44ebMmeNGjRrl0tLS3NixY92SJUsG3JO0s339ktzatWu7tzl58qT79re/7S655BI3ZMgQd8stt7jGxka7RfeA8x2HgwcPupkzZ7rs7GwXiUTc5Zdf7r73ve+51tZW24V/Dr+OAQBgos+/BgQAGJgoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCY+P+8RmwV/Q3TIgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You can put between 0 to 59999 here\n",
    "index = 6632\n",
    "\n",
    "# Set number of characters per row when printing\n",
    "np.set_printoptions(linewidth=320)\n",
    "\n",
    "# Print the label and image\n",
    "print(f'LABEL: {training_labels[index]}')\n",
    "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
    "\n",
    "# Visualize the image\n",
    "plt.imshow(training_images[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values of the train and test images\n",
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a callback to stop training at 90% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy') >= 0.9):\n",
    "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "    \n",
    "    if(logs.get('loss') < 0.4):\n",
    "      print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Sequential`: Defines sequence of layers in neural networks\n",
    "- `Flatten`: Converts 28 x 28 2D array into a 1D array\n",
    "- `Dense`: Adds a layer of neurons\n",
    "\n",
    "Activation Functions\n",
    "- `Relu`: If x > 0 return x, else return 0\n",
    "- `Softmax`: Takes a set of values and picks the biggest one (probability). In our example, if biggest one is in index 4, then the label of image is 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the classification model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 809us/step - loss: 0.4929 - accuracy: 0.8252\n",
      "Epoch 2/10\n",
      "1825/1875 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.8658\n",
      "Loss is lower than 0.4 so cancelling training!\n",
      "1875/1875 [==============================] - 2s 827us/step - loss: 0.3717 - accuracy: 0.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ebef2590>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model's performance on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 561us/step - loss: 0.3850 - accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3850407004356384, 0.8600000143051147]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on unseen data\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of classification for each of the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "[3.6783596e-05 9.0544563e-07 2.5116453e-05 7.8936580e-05 2.9542980e-05 1.6380265e-02 1.0681361e-04 6.8054788e-02 7.1403603e-03 9.0814650e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN) for Fashion-MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               102528    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113386 (442.91 KB)\n",
      "Trainable params: 113386 (442.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "MODEL TRAINING:\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4762 - accuracy: 0.8279\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3141 - accuracy: 0.8857\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2695 - accuracy: 0.8997\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2394 - accuracy: 0.9103\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2166 - accuracy: 0.9195\n",
      "\n",
      "MODEL EVALUATION:\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.9024\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "                                                         \n",
    "  # Add convolutions and max pooling\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "  # Add the same layers as before\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Use same settings\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "print(f'\\nMODEL TRAINING:')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluate on the test set\n",
    "print(f'\\nMODEL EVALUATION:')\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
