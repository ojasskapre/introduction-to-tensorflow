{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Unzip training set\n",
    "local_zip = './happy-or-sad.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./happy-or-sad')\n",
    "\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training happy images: 40\n",
      "total training sad images: 40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory with training happy pictures\n",
    "train_happy_dir = os.path.join('./happy-or-sad/happy')\n",
    "\n",
    "# Directory with training sad pictures\n",
    "train_sad_dir = os.path.join('./happy-or-sad/sad')\n",
    "\n",
    "print(f'total training happy images: {len(os.listdir(train_happy_dir))}')\n",
    "print(f'total training sad images: {len(os.listdir(train_sad_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET HAPPY: ['happy1-19.png', 'happy1-18.png', 'happy1-08.png', 'happy1-09.png', 'happy2-17.png', 'happy2-03.png', 'happy2-02.png', 'happy2-16.png', 'happy2-00.png', 'happy2-14.png']\n",
      "TRAIN SET SAD: ['sad1-09.png', 'sad1-08.png', 'sad1-18.png', 'sad1-19.png', 'sad2-10.png', 'sad2-04.png', 'sad2-05.png', 'sad2-11.png', 'sad2-07.png', 'sad2-13.png']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_happy_names = os.listdir(train_happy_dir)\n",
    "print(f'TRAIN SET HAPPY: {train_happy_names[:10]}')\n",
    "\n",
    "train_sad_names = os.listdir(train_sad_dir)\n",
    "print(f'TRAIN SET SAD: {train_sad_names[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_happy_pix = [os.path.join(train_happy_dir, fname) \n",
    "                for fname in train_happy_names[pic_index-8:pic_index]]\n",
    "next_sad_pix = [os.path.join(train_sad_dir, fname) \n",
    "                for fname in train_sad_names[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_happy_pix+next_sad_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a model with 5 convolutions and pooling layers and then flatten the result to feed it to the dense layers. Since it is a binary classification we have 1 neuron in output layer with sigmoid activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 148, 148, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPooli  (None, 74, 74, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPooli  (None, 36, 36, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPooli  (None, 17, 17, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 15, 15, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1667169 (6.36 MB)\n",
      "Trainable params: 1667169 (6.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training dataset using ImageDataGenerator. Loads training images of horse and humans from the directory and resizes them to 300x300 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './happy-or-sad/',  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 300x300\n",
    "        batch_size=10,\n",
    "        # Since you use binary_crossentropy loss, you need binary labels\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a callback for accuracy >= 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True    \n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the dataset for 15 epochs. Since we have 1024 images with batch size 128, steps per epoch is 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.7333 - accuracy: 0.5875\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.5465 - accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2180 - accuracy: 0.9375\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.1282 - accuracy: 0.9250\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0523 - accuracy: 0.9875\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 1.0000\n",
      "Reached 99.9% accuracy so cancelling training!\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0388 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      epochs=20,\n",
    "      verbose=1,\n",
    "      callbacks=[callbacks])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
